[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "GatAI v. X-Mas-3",
    "section": "",
    "text": "/\\_/\\\n ( o.o )\n  &gt; ^ &lt;\n\n\n\n\n\nGatai, the AI\nOne smart cat\n\n\n\n\nPreface\nIn August of 2023, I undertook to do some exploratory research on video-games available on the Gato (2023) social gaming platform. The purpose of this exercise was to better understand the potential problem space and the application of artificial intelligence (AI) to some of its extent. This volume is a write-up of some of the results and experiences, and furthermore a chronicle of the process I followed.\n\n\n\n\n\nIn the Red Corner:\nOur Nemesis\nX-Mas-3\n\n\n\n    *\n    /\\\n   //\\\\\n  ///\\\\\\\n ////\\\\\\\\\n/////\\\\\\\\\\\n   [][]\n\n\n\n\n\n\n\n“Gato: The Free Social Gaming Platform for All.” 2023. https://www.gato.us."
  },
  {
    "objectID": "x-mas-3-description.html#setup-and-purpose",
    "href": "x-mas-3-description.html#setup-and-purpose",
    "title": "1  The Game",
    "section": "1.1 Setup and Purpose",
    "text": "1.1 Setup and Purpose\nWhen starting the game a 6 by 10 grid with different shaped and colored tiles is displayed. These are Christmas-themed, i.e. trees, santas’ hats, candy and various Christmas ornaments. There is a total of ten different types of tiles. An example of a X-mas-3 board can be seen in Figure 1.1.\n\n\n\nFigure 1.1: Screenshot of X-mas-3 Board\n\n\nThe purpose of the game is to move the tiles so that combination of 3, 4 or 5 like tiles appear in the same row or column."
  },
  {
    "objectID": "x-mas-3-description.html#rules-and-scoring",
    "href": "x-mas-3-description.html#rules-and-scoring",
    "title": "1  The Game",
    "section": "1.2 Rules and Scoring",
    "text": "1.2 Rules and Scoring\nThe tiles can move one position vertically or horizontally. When a tile is moved the space it occupied is occupied by the tile in the target cell, i.e. they swap places. In the arcade mode version of the game the number of moves is limited to 100. There is also a time mode version which allows for unlimited moves within a given time-frame. If the move results in one or several 3, 4 or 5 tile combination on the board, these tiles disappear and the tiles above “fall” into the empty spaces created. This is repeated for the subsequent rows and the empty spaces left in the top row are replaced by random tiles, with the limitation that this replacement will not result in additional scoring.\nThe scoring is 50, 100 and 200 points for 3, 4 and 5 tiles is a row/column respectively1.\n\n\n\n\nPro Games Studio. 2023. “X-MAS-3.” https://www.gato.us."
  },
  {
    "objectID": "x-mas-3-description.html#footnotes",
    "href": "x-mas-3-description.html#footnotes",
    "title": "1  The Game",
    "section": "",
    "text": "These rules were derived from this researcher’s actual play of the game. We have no official rules, and the description limits itself to “score points by”.↩︎"
  },
  {
    "objectID": "abstracting-x-mas-3.html#abstracting-the-board-and-tiles",
    "href": "abstracting-x-mas-3.html#abstracting-the-board-and-tiles",
    "title": "2  Abstracting X-Mas-3",
    "section": "2.1 Abstracting the Board and Tiles",
    "text": "2.1 Abstracting the Board and Tiles\nThe board is a 6 by 10 grid each containing a tile out of ten different tile-types. For our purposes we represent the board as a 6x10 matrix with the letters A through J representing the ten different tiles. An example board would me represented thus:\n\\[\\begin{bmatrix} G & C & J & D & G & G & C & G & B & A \\\\ I & D & E & A & C & B & H & C & E & F \\\\ J & C & J & F & C & J & A & H & B & F \\\\ H & C & D & F & C & F & D & B & G & B \\\\ D & I & H & I & I & B & F & C & C & E \\\\ B & F & A & J & E & H & I & C & H & G \\end{bmatrix}\\]\n\nChecking for Combinations\nUsing this structure we can check for the presence of combinations using regular expressions. Using\n\\[\n\\text{([A-J])\\\\1\\\\1+}\n\\]\nas a regular expression will identify three or more consecutive occurrences of similar tiles. Implemented in R below:\n\n\nCode\nget_n_combinations &lt;- \\(m){\n  my_regex &lt;- \"([A-J])\\\\1\\\\1+\"  \n    rowmatch &lt;- purrr::map_lgl(1:6,~{\n    my_str &lt;- stringr::str_c(m[.x,], collapse = \"\")\n    grepl(my_regex,my_str) \n  })\n  colmatch &lt;-purrr::map_lgl(1:10,~{\n    grepl(my_regex,stringr::str_c(m[,.x], collapse = \"\")) \n  })\n  sum(colmatch,rowmatch)\n}\n\n\nIn this case one match is returned because of the triple “C”s found in column 5.\n\n\nInitial Board State\nSince the initial state of the board cannot include any scoring combination we need a function that generates a random initial state until the board’s score is zero. We implemented this recursively.\n\n\nCode\ninitialize_board &lt;- \\(){\n  tiles &lt;- LETTERS[1:10]\n board &lt;- matrix(data = sample(tiles,60,replace = TRUE),6,10)\n  ## If the initial state scores, generate another one\n  if(get_n_combinations(board)&gt;0){\n    board &lt;- initialize_board()\n  }\n board\n}\ninitialize_board()\n\n\n\n\nMaking Moves\nMoves are made by specifying a cell, (by clicking on it) and then switching it with one of it’s neighbors directly above, below, to the left or to the right. When a move is made the neighboring tile switches places with the first one clicked."
  },
  {
    "objectID": "abstracting-x-mas-3.html#applying-reinforcement-learning",
    "href": "abstracting-x-mas-3.html#applying-reinforcement-learning",
    "title": "2  Abstracting X-Mas-3",
    "section": "2.2 Applying Reinforcement Learning",
    "text": "2.2 Applying Reinforcement Learning\nReinforcement Learning (RL) (Watkins and Dayan 1992) is an algorithm that allows an agent (i.e. AI) to interact with an environment over a sequence of observations. The agent seeks to be rewarded and for the reward to be maximized over time. The model consists of a set of environment states \\(S\\) a set of actions \\(A\\) and a set of rewards \\(R\\) (positive or negative).\nThe algorithm is guaranteed to converge to an optimal policy for each possible state in \\(S\\). RL (and in this case we will use Q-learning) needs to be trained on a set of state-transition tuples formally defined in 2.1. \\[\n(s_i, a_i, r_{i+1}, s_{i+1})\n\\tag{2.1}\\]\nwhere:\n\n\\(s_i\\) is the current environment state,\n\\(a_i\\) is selected action in the current state,\n\\(r_{i+1}\\) represents the reward, and,\n\\(s_{i+1}\\) is the resulting state.\n\n\nSpecifying our Spaces\nFor \\(S\\) we have ten possibilities for each of the 60 (\\(6\\times10\\)) cells on our board. For \\(A\\) the agent can make one out of four moves in each of the 60 cells (ignoring for the moment the marginal cases of moving off the board, which is not possible). As for the reward space \\(R\\), this can probably be set to the actual scores of the game, with some smaller penalty for making a non-scoring move or Passing (subsequent analysis will make it clear why this needs to be a possibility for practical purposes).\n\n\nReducing our Spaces\nFor our \\(S\\) as defined above the number of possible states is \\(10^{60}\\), which is a 1 followed by 60 zeros, i.e.:\n\n\n\n\n\n      |\\__/,|   (`\\\n    _.|o o  |_   ) )\n---(((---(((---------\n\n\nWow, that's a huge number!\n\n\n\\(10^{60}\\) = 1,000, 000, 000, 000, 000, 000, 000, 000, 000, 000, 000, 000, 000, 000, 000, 000, 000, 000, 000, 000.\nThe action space \\(A\\) is slightly smaller since there are only four possibilities for each cell, so we have “only” \\(4^{60}\\) which is roughly equal to \\(1.329\\times10^{36}\\).\nGiven the magnitude of these numbers it is clear that we cannot reasonably expect the algorithm to converge for several millennia with the computing power currently at our disposal. We therefore need to employ some strategies for reducing the spaces.\n\nOne Type at a Time\nWe can consider a one-type-at-a-time strategy. The heuristic implemented would then be to first look for moves involving candy, then move on to trees and so on. For example: staring with an initial board like this:\n\\[\\begin{bmatrix} G & C & J & D & G & G & C & G & B & A \\\\ I & D & E & A & C & B & H & C & E & F \\\\ J & C & J & F & C & J & A & H & B & F \\\\ H & C & D & F & C & F & D & B & G & B \\\\ D & I & H & I & I & B & F & C & C & E \\\\ B & F & A & J & E & H & I & C & H & G \\end{bmatrix}\\]\nAnd chose to consider the “A” cells we get:\n\\[\\begin{bmatrix} 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\ 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 1 & 0 & 0 & 0 & 0 & 1 & 1 & 0 \\\\ 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & 0 & 1 & 1 & 0 & 0 \\end{bmatrix}\\]\nThis reduces the problem to a binary one and we effectively reduce \\(S\\) to \\(2^{60}\\), which is merely 1.15 quintillions. While this represents a huge reduction, it is still far from being feasible. In addition this does not reduce our action space \\(A\\), as you still have four possible moves for each of the 60 cells.\n\n\nWindowing\nWe can further reduce our problem space by applying a technique known as windowing. This implies dividing the grid into sub-grids and looking for playable moves within those reduced spaces. If we first consider the quest for a three-tile combinations, the windows in question would be a \\(3\\times2\\) and a \\(2\\times3\\) sub-matrix for perpendicular (\\(\\perp\\))moves. For parallel (\\(\\parallel\\)) moves, i.e. moves with the same row or column we would have to consider \\(1\\times4\\) and \\(4\\times1\\) respectively. Examples are shown below.\n\\[\\begin{bmatrix} 1 & 1 & 0 \\\\ 0 & 1 & 1 \\end{bmatrix}\n%\n\\text{ or}\n%\n\\begin{bmatrix} 1 & 0 \\\\ 1 & 1 \\\\ 0 & 1 \\end{bmatrix}\n%\n\\text{ for }\\perp\\text{moves,}\\]\nand\n\\[\\begin{bmatrix} 1 & 1 & 0 & 1 \\end{bmatrix}\n%\n\\text{ or}\n%\n\\begin{bmatrix} 1 \\\\ 1 \\\\ 0 \\\\ 1 \\end{bmatrix}\n%\n\\text{ for }\\parallel \\text{ moves.}\\]\nIs it easy to see that the \\(3\\times2\\) matrix above is a transposition of the \\(2\\times3\\) one, and therefore it does not matter whether a move if horizontal or vertical the problem is similar in nature for all perpendicular moves. The same is true for the \\(4\\times1\\) and \\(1\\times4\\) matrices, i.e. where there is a winning parallel move. Matrix 2.2 illustrates two windows on our original board and Matrix 2.3 shows the same in our binary space (combining the two reduction strategies).\n\\[\n\\begin{bmatrix} G & \\color{red}{\\textbf{C}} & \\color{red}{\\textbf{J}} & \\color{red}{\\textbf{D}} & \\color{red}{\\textbf{G}} & G & C & G & B & A \\\\ I & D & E & A & C & B & H & C & E & F \\\\ J & C & J & F & C & J & \\color{red}{\\textbf{A}} & \\color{red}{\\textbf{H}} & B & F \\\\ H & C & D & F & C & F & \\color{red}{\\textbf{D}} & \\color{red}{\\textbf{B}} & G & B \\\\ D & I & H & I & I & B & \\color{red}{\\textbf{F}} & \\color{red}{\\textbf{C}} & C & E \\\\ B & F & A & J & E & H & I & C & H & G \\end{bmatrix}\n\\tag{2.2}\\]\n\\[\n\\begin{bmatrix}\n0 & \\color{red}{\\textbf{1}} & \\color{red}{\\textbf{0}} & \\color{red}{\\textbf{0}} & \\color{red}{\\textbf{0}} & 0 & 1 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 1 & 0 & 0 & 1 & 0 & 0 \\\\\n0 & 1 & 0 & 0 & 1 & 0 & \\color{red}{\\textbf{0}} & \\color{red}{\\textbf{0}} & 0 & 0 \\\\\n0 & 1 & 0 & 0 & 1 & 0 & \\color{red}{\\textbf{0}} & \\color{red}{\\textbf{0}} & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 & \\color{red}{\\textbf{0}} & \\color{red}{\\textbf{1}} & 1 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0\n\\end{bmatrix}\n\\tag{2.3}\\]\n\n\nThe Reduced Action Spaces\nIf we employ the windowed approach suggested above, our action space, \\(A\\) shrinks significantly. We will in fact have two different \\(S\\) and \\(A\\) depending on whether we are considering parallel or perpendicular moves.\nFor a parallel window, we can generalize to the horizontal variant (since the horizontal one is a simple transposition thereof) and we then get only a few relevant combinations. Since any four element set which already has three in a row is will not occur, we are left with: {0000,0001,0010,0011,0100,0101,0110,1000,1001,1011, 1101} for a total of 11 cases out of which only two have a winning move ({1011, 1101}). This reduces \\(A_{\\parallel}\\) for \\(S_{\\parallel}\\) to three moves: pass (P), flip first (F) or flip last (L). formalized in Equation 2.4.\n\\[\nA_{\\parallel} = \\{P,F,L\\}\n\\tag{2.4}\\]\nFor the perpendicular case we 62 combinations, these are illustrated in Equation 2.5.\n\\[\nS_{\\perp} = \\Biggl\\{ \\left[{000\\atop{000}}\\right],\n\\left[{000\\atop{001}}\\right],\n\\left[{000\\atop{010}}\\right] ...\n\\left[{001\\atop{001}}\\right],\n\\left[{001\\atop{010}}\\right]...\n\\left[{110\\atop{011}}\\right]\n\\Biggr\\}\n\\tag{2.5}\\]\nThe action space is limited to flipping one out of three positions, First, Middle, Last, or Passing. Illustrated in Equation 2.6.\n\\[\nA_{\\perp}=\\{F,M,L,P\\}\n\\tag{2.6}\\]\n\n\n\nCaveats\nThe windowed approach proposed above, along with the one-type-at-a-time technique reduce our \\(A\\) and \\(S\\) to magnitudes that are manageable and allow us to generate a training set. They do limit the potential for the agent in some non-trivial ways, namely:\n\nThe Agent will only look for combinations of three tiles, and\nThe agent will only look one move ahead.\n\nIn view of (2) the more precise description of our endeavor is perhaps to say that we are teaching it tactics rather than strategy.\nWe will later see if it is feasible to generalize this approach and create larger grids."
  },
  {
    "objectID": "abstracting-x-mas-3.html#algebraic-notation",
    "href": "abstracting-x-mas-3.html#algebraic-notation",
    "title": "2  Abstracting X-Mas-3",
    "section": "2.3 Algebraic Notation",
    "text": "2.3 Algebraic Notation\nIn order to facilitate the discussion and analysis of positions and moves I decided to use notation inspired by algebraic notation in the game of chess. Our board is 6x10 (as opposed to 8x8 in chess), so we have columns A through J, and rows 1 through 6. Since there is a component of “gravity” in the game, i.e. tiles fall toward the botton of the screen when tiles are removed from the board, I decided to number rows from the top. This would be congruent with the typical layout of a chess board, but seen from the perpective of the black pieces. An example can be seen in Figure 2.1.\n\n\n\n\n\nFigure 2.1: An Example Board\n\n\n\n\nMoving the top-left tile to the adjecent square to the right would be denoted: “A1 to B1” or simply “A1B1”. The move is illustrated in Figure 2.2.\n\n\n\n\n\nFigure 2.2: The Move A1 to B1"
  },
  {
    "objectID": "abstracting-x-mas-3.html#transpositions",
    "href": "abstracting-x-mas-3.html#transpositions",
    "title": "2  Abstracting X-Mas-3",
    "section": "2.4 Transpositions",
    "text": "2.4 Transpositions\nSince the strategies and tactics learned on a i.e. 3x4 board are in principle the same as those of a 4x3 board it is useful to be able to transpose both boards and moves. We therefore implemented transpose-functions for both.\n\nExamples\n\n\n\n\n\n\n\n(a) Original\n\n\n\n\n\n\n\n(b) Transposed\n\n\n\n\nFigure 2.3: Transposition example"
  },
  {
    "objectID": "abstracting-x-mas-3.html#windowing-and-sliding",
    "href": "abstracting-x-mas-3.html#windowing-and-sliding",
    "title": "2  Abstracting X-Mas-3",
    "section": "2.5 Windowing and Sliding",
    "text": "2.5 Windowing and Sliding\nAnother class of transpositions applies to those that are either horizontal or vertical, but do not imply a flip around the matrix’s diagonal. For the avoidance of confusion I chose to denominate these operations as sliding. And the origin area of a slide a window.\nSince we are operating on simplified sub-boards, and part of our strategy is to window the playing-board we implemented functions to window a board, i.e. subdivide it into smaller pieces for analysis. When moves are suggested for the sub-division we need to slide these moves over on the real playing board (i.e. the larger one).\n\nExamples\n\n\n\n\n\n\n\n(a) Board with Window\n\n\n\n\n\n\n\n(b) Moves A1xA2 and B1xA1\n\n\n\n\n\n\n\n(c) Transitioned Moves\n\n\n\n\nFigure 2.4: Example of windowing\n\n\n\n\n\n\nISO. 2012. ISO/IEC 14882:2011 Information technology — Programming languages — C++. Geneva, Switzerland: International Organization for Standardization. http://www.iso.org/iso/iso_catalogue/catalogue_tc/catalogue_detail.htm?csnumber=50372.\n\n\nR Core Team. 2023. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/.\n\n\nWatkins, Christopher JCH, and Peter Dayan. 1992. “Q-Learning.” Machine Learning 8: 279–92."
  },
  {
    "objectID": "model-training.html#functions-needed",
    "href": "model-training.html#functions-needed",
    "title": "3  Model Training",
    "section": "3.1 Functions Needed",
    "text": "3.1 Functions Needed\nFor the purposes of setting up the agent training for an \\(m\\times{n}\\) board, we implemented the following functions.\n\ncreate_state_space\n\n\nCode\ncreate_state_space &lt;- \\(nrow=3, ncol=3){\n  classname &lt;- paste0(nrow,\"x\",ncol,\".space\")\n  S &lt;- 0:(2^(ncol*nrow)-1)\n  purrr::map(S,~{\n   xmas3board(.x,dims = c(nrow,ncol))\n  })\n}\n\n\nThis function returns a list of integers with the appropriate class (mostly for printing and debugging.)\n\n\ncreate_action_space\nThis function generates an action space in chess notation given a grid on ncol and nrows.\n\n\nCode\ncreate_action_space &lt;-\\(nrows=3, ncols=3){\n  my_cols &lt;- LETTERS[1:ncols]\n  my_rows &lt;- 1:nrows\n  A &lt;- c()\n  # Vertical moves\n  for(.r in 1:(length(my_rows))){\n    for(.c in 1:(length(my_cols)-1)){\n      A &lt;- c(A,\n             paste0(\n               my_cols[.c],my_rows[.r],\n               \" to \",\n               my_cols[.c+1],my_rows[.r]\n             )\n      )\n    }\n  }\n  \n  # Horizontal\n  for(.c in 1:(length(my_cols))){\n    for(.r in 1:(length(my_rows)-1)){\n      A &lt;- c(A,\n             paste0(\n               my_cols[.c],my_rows[.r],\n               \" to \",\n               my_cols[.c],my_rows[.r+1]\n             )\n      )\n    }\n  }\n  c(A,\"Pass\")\n}\n\n\n\n\nmake_move\nThis function takes as input a board B and a move (in chess notation). It makes the move and returns the resulting board.\n\n\nCode\nmake_move &lt;- \\(B, move){\n  \n  # If no move is made the board remains unaltered\n  if(move == \"Pass\") return(B) \n  \n  # Parse out move\n  M &lt;- as.matrix(B)\n  m &lt;- parse_move(move)\n  r1&lt;-m$rs[1];r2&lt;-m$rs[2];c1&lt;-m$cs[1];c2&lt;-m$cs[2]\n  tmp &lt;- M[r2,c2]\n  M[r2, c2] &lt;- M[r1,c1]\n  M[r1, c1] &lt;- tmp\n  M |&gt;  adana::bin2int() |&gt;\n    xmas3board(dims =attr(B, \"dims\") )\n  \n}\n\n\n\n\nscore_binary_board\nThis function takes as input a binary matrix and calculates the resulting score according to the rules of X-mas-3.\n\n\nCode\nscore_binary_board &lt;-\\(B){\n  if(!is.matrix(B)) B &lt;- as.matrix(B)\n  \n  # Magic numbers here are:\n  # 7,14,28 - three in a row/col\n  # 15, 30 - four in a row/col\n  # 31 - five in a row\n  rows &lt;- \n    apply(B,1,function(x){\n      v &lt;- paste0(x, collapse = \"\")\n      strtoi(v,2)\n    })\n  \n  cols &lt;- \n    apply(B,2,function(x){\n      v &lt;- paste0(x, collapse = \"\")\n      strtoi(v,2)\n    })\n  \n  totals &lt;- c(cols,rows)\n  \n  score &lt;- sum(\n             sum(totals%in%c(7,14,28))*50,\n             sum(totals%in%c(15,30))*100, \n             sum(totals%in%c(31))*200\n             )\n  score\n}\n\n\nThese functions will allow us to create the input needed to train a Reinforcement Learning (RL) model."
  },
  {
    "objectID": "model-training.html#procedure",
    "href": "model-training.html#procedure",
    "title": "3  Model Training",
    "section": "3.2 Procedure",
    "text": "3.2 Procedure\nWe will attempt to train models for each of the grid-sized mentioned above. However, it is likely that not all sizes will converge. In fact, our prediction is that we will not make it past 3x6 ~ 6x3."
  },
  {
    "objectID": "model-training.html#the-3x3-board",
    "href": "model-training.html#the-3x3-board",
    "title": "3  Model Training",
    "section": "3.3 The 3x3 Board",
    "text": "3.3 The 3x3 Board\nWe start with a 3x3 grid. This should be sufficiently small that a machine learning algorithm will converge in short order and we are able to test the outcome before embarking on a more wide-ranging training activities.\n\nState Space\nA three by three board gives us a state-space of 512 possibilities. However, some proportion of the boards in this space will already have a winning combination on them, and should be excluded form the training because (a) they will not come up in play, as tiles are immediately removed when a scoring combination is found, and (b) there is logically no correct move on these boards. For example Board 56 has three touching tiles in column B.\n\n\n\n\n\nFigure 3.1: Board 56\n\n\n\n\nWe will remove these from consideration by generating the action space, scoring each board and removing the ones that have a positive score.\n\nS &lt;- create_state_space(3,3)\nmy_scores &lt;- purrr::map(S,score_binary_board) %&gt;% unlist()\nS &lt;- S[my_scores==0] \n\nWhich leaves us with 265 playable boards.\n\n\nAction Space\nOur action space A is created using the functions from our package\n\nA &lt;- xmas3::create_action_space(3,3)\nA |&gt; paste(collapse = \", \") |&gt; cat()\n\nA1 to B1, B1 to C1, A2 to B2, B2 to C2, A3 to B3, B3 to C3, A1 to A2, A2 to A3, B1 to B2, B2 to B3, C1 to C2, C2 to C3, Pass\n\n\nWhich gives us a an A of length 13 .\n\n\nData for Modelling\nThe data for the modelling exercise was created by playing each possible move for each of the remaining S.\n\n\nTraining the Model\nWe then applied the Q-learning algorithm (Watkins and Dayan 1992) implemented in the open source ReinforcementLearning package (Proellochs and Feuerriegel 2020), with the standard default parameters (\\(\\alpha=.1,\\gamma=.1, \\epsilon=.1\\)).\n\n\nTesting the Model\nWe can now test the model by asking it to play some boards where we know the correct play. For example \\(S_{32}\\) where there is a scoring move.\n\nS[[32]]\n\n| · O · |\n| · · O |\n| · · O |\n\n\n\n# Read from cache\ngatai &lt;- readr::read_rds(here::here(\"models\",\"q-learning-3x3.rds\"))\ngatai |&gt; predict(S[32])\n\n[1] \"B1 to C1\"\n\n\n\n\n\n\n\n\n\n(a) Space 32\n\n\n\n\n\n\n\n(b) Suggested Move\n\n\n\n\nFigure 3.2: State Space 32\n\n\nOn the other hand \\(S_{4}\\) does not have a scoring move and should be passed. The same is true for \\(S_{6}\\)\n\nS[[4]]\nS[[6]]\n\n\n\n| · · · |\n| · · O |\n| · · O |\n\n\n| · · O |\n| · · · |\n| · · O |\n\n\n\n\n\ngatai |&gt; predict(c(S[4],S[6])) |&gt; cat()\n\nPass Pass\n\n\n\n\n\n\n\n\n\n(a) Space 4\n\n\n\n\n\n\n\n(b) Space 6\n\n\n\n\nFigure 3.3: State Spaces 4 and 6\n\n\n\nCompeting Moves and Strategy\nBoard 263 is an interesting case. Since there are three moves that would score points. However two of them are strategically superior (A1 to A1 and C1 to C2), because they both guarantee that there is enough tiles left on the board to make a scoring move on the next round.\n\n\n\n\n\n\n\n(a) Board\n\n\n\n\n\n\n\n(b) Scoring Moves\n\n\n\n\n\n\n\n(c) Strongest Moves\n\n\n\n\nFigure 3.4: Board 263\n\n\nLet’s see what Gatai believes:\n\ngatai |&gt; predict(S[263])\n\n[1] \"B1 to C1\"\n\n\nSo, one of the strongest moves available. However, we cannot be sure whether this was a random choice among scoring moves or the result of a strategic play. We can check this with another board.\n\n\nStrategic Moves\nIn our original State space $_{259} does not have a directly scoring move, however, the correct move is A1 to B1, in preparatin for B1xC1 on the next round.\n\nB &lt;- xmas3board(259,c(3,3))\nB\n\n| O · · |\n| · · O |\n| · · O |\n\n\n\ngatai |&gt; predict(B[1])\n\n[1] \"A1 to B1\"\n\n\nSo we see that Gatai is capable of making strategic moves as well.\n\n\n\n\n\n\n\n(a) Initial Board\n\n\n\n\n\n\n\n(b) Suggested Move and Projection\n\n\n\n\nFigure 3.5: Gatai Thinks Ahead\n\n\n\n\n\n\n\n  /\\_/\\\n (⌐■_■ ) \n  &gt; ^ &lt;\n\n\nCool model."
  },
  {
    "objectID": "model-training.html#the-3x4-board",
    "href": "model-training.html#the-3x4-board",
    "title": "3  Model Training",
    "section": "3.4 The 3x4 Board",
    "text": "3.4 The 3x4 Board\n\nState Space\nWith the grid dimension chosen, we have \\(2^{(3\\times4)}=4096\\), possibilities. This should still be within the realm of the possible given the resources available.\n\n\nAction Space\nThe action space \\(A\\) has a cardinality of 19.\n\n\nData for Modelling\nThe data for the modelling exercise was created by playing each possible move for each of the remaining S.\n\n\nTraining the Model\nWe trained the same type of model (Q-Learning) as before, again with the standard default parameters (\\(\\alpha=.1,\\gamma=.1, \\epsilon=.1\\)). This model converged in just over 8 seconds.\n\n\nTesting the Model\nAgain we can now test the model by asking it to play some boards where we know the correct play. For example \\(S_{32}\\) where there is a scoring move.\n\nSpot Checks\nLet’s do a spot_check.\n\n# Read from cache\ngatai &lt;- readr::read_rds(here::here(\"models\", \"q-learning-3x4.rds\"))\nS[[32]]\n\n| · · O · |\n| · · · O |\n| · · · O |\n\ngatai |&gt; predict(S[32])\n\n[1] \"C1 to D1\"\n\n\nLooks good. Let’s check a non-scoring one.\n\nS[[33]]\n\n| · · O O |\n| · · · · |\n| · · · · |\n\ngatai |&gt; predict(S[33])\n\n[1] \"Pass\"\n\n\nSo, it seems we have an somewhat intelligent model. Let’s see if it can think strategically at this level.\n\nB &lt;- xmas3board(2051 ,c(3,4))\nB\n\n| O · · · |\n| · · · O |\n| · · · O |\n\ngatai |&gt; predict(B[1])\n\n[1] \"A1 to B1\"\n\n\nSo, apparently looking three moves ahead.\n\n\n\n\n\n\n\n(a) Board 2051\n\n\n\n\n\n\n\n(b) Suggested Move\n\n\n\n\nFigure 3.6: Gatai Thinks Three Moves Ahead\n\n\n\n\nCompeting Moves\nBoard 2699 has two possible solutions. One scores higher than the other\n\nB &lt;- xmas3board(2699, c(3,4))\nB\n\n| O · · · |\n| · O · O |\n| O · O O |\n\ngatai |&gt; predict(B[1]) \n\n[1] \"B2 to B3\"\n\n\nWe see that Gatai chooses the highest scoring move.\n\n\n\n\n\n\n\n(a) Scoring Moves for Board 2699\n\n\n\n\n\n\n\n(b) Gatai’s Move\n\n\n\n\nFigure 3.7: Gatai Chooses Highest Scoring Move\n\n\n\n\n\n\n\n\n  /\\_/\\\n ( $.$ )\n  &gt; ^ &lt;\n\n\nIn it to win it, baby."
  },
  {
    "objectID": "model-training.html#training-above-3x4",
    "href": "model-training.html#training-above-3x4",
    "title": "3  Model Training",
    "section": "3.5 Training above 3x4",
    "text": "3.5 Training above 3x4\nWe followed the same procedure as in the previous cases with similar results. As predicted the last model to converge was the one for the 3x6 grid. This took approximately 4 hours.\n\n\n\n\nProellochs, Nicolas, and Stefan Feuerriegel. 2020. “ReinforcementLearning: Model-Free Reinforcement Learning.”\n\n\nWatkins, Christopher JCH, and Peter Dayan. 1992. “Q-Learning.” Machine Learning 8: 279–92."
  },
  {
    "objectID": "full-board-strategies.html#applicable-models",
    "href": "full-board-strategies.html#applicable-models",
    "title": "4  Full Board Strategies",
    "section": "4.1 Applicable Models",
    "text": "4.1 Applicable Models\nFrom the model training already performed we have a total of six models: 3x3, 3x4, 3x5, 3x6 and 4x4, for sub-boards (windowed grids) as well as their relevant transpositions. Any of these can be used to scan the entire board looking for playable moves or move sequences (i.e. strategic moves) by using the windowing technique already described. Each evaluation of a sub-boards will return a best move or move-sequence and expected value of the sequence (which may be of cardinality 1). We may have some intuition about which strategy is optimal, e.g. all 3x3 sub-boards are included in a series of other geometries (3x4, 3x5, 3x6 and 4x4), and the best strategy can be derived mathematically. We chose the statistics route to the optimal strategy."
  },
  {
    "objectID": "full-board-strategies.html#monte-carlo-simulations",
    "href": "full-board-strategies.html#monte-carlo-simulations",
    "title": "4  Full Board Strategies",
    "section": "4.2 Monte Carlo Simulations",
    "text": "4.2 Monte Carlo Simulations\nWe conducted Monte Carlo simulations of ten thousand (10,000) random boards, each played with each of the available geometries. This is the equivalent of playing 100 games (in arcade mode) with each strategy. The score on the move, number of moves and expected score per move (relevant if strategic moves are made) were calculated as well. The summary statistics are shown in Figure 4.1 and Table 4.1 respectively.\n\n\n\n\n\nFigure 4.1: Boxplot of Expected Values for the ‘Best Move’ Strategy, by Geometry\n\n\n\n\n\n\n\n\nTable 4.1: Expected Score by Geometry\n\n\ngeometry\nMedian\nMean\nSD\n\n\n\n\n3x3\n50\n48.880\n5.244\n\n\n3x4\n50\n50.394\n8.087\n\n\n3x5\n50\n52.312\n13.114\n\n\n4x4\n50\n53.680\n14.004\n\n\n5x3\n50\n52.928\n14.743\n\n\n6x3\n50\n52.075\n14.221\n\n\n\n\n\n\nWe can see that the 4x4 geometry is marginally superior when using the best move strategy.\n\nTime of Evaluation\nAs we will be developing full board strategies for both arcade and time mode in the actual game, we also analyzed the time it took Gatai to evaluate the boards using each of the geometries. The results are shown in Figure 4.2.\n\n\n\n\n\nFigure 4.2: Time per Move by Geometry\n\n\n\n\nWe see that the larger geometries have shorter evaluation times, which makes logical sense: time-per sub-board is relatively stable, but the larger geometries have fewer unique evaluations. However, optimizing for time, the larger overhead will likely be the application of the vision model, so that the relatively small time-differences is a minor issue in comparison."
  },
  {
    "objectID": "full-board-strategies.html#optimal-strategies",
    "href": "full-board-strategies.html#optimal-strategies",
    "title": "4  Full Board Strategies",
    "section": "4.3 Optimal Strategies",
    "text": "4.3 Optimal Strategies\n\nArcade\nFor the arcade version of the game it is clear that we should use the geometry which optimizes the expected score per move, as the only constraint we have here is that we have 100 moves to complete the game.\n\n\nTime Mode\nPlaying X-mas-3 via the graphical user interface adds significant overhead because of the image processing needed. However playing a series of pre-defined moves on the board has relatively low overhead. This suggests a strategy that will optimize the number of playable moved on the board per unit time.\n\n\n\n\n\n\n\n /\\___/\\\n \\ -.- /\n `-.^.-'\n   /\"\\      \n\n\nBe afraid, Chris. Be very afraid..."
  },
  {
    "objectID": "computer-vision-model.html#interacting-with-the-gui",
    "href": "computer-vision-model.html#interacting-with-the-gui",
    "title": "5  Computer Vision",
    "section": "5.1 Interacting with the GUI",
    "text": "5.1 Interacting with the GUI\nAs we did not have access to the source code, we were left with the latter option: interacting with the GUI. This avenue presented us with some additional challenges, most of which are, incidentally, solvable by applying artificial intelligence.\n\n\nThere is, of course, the third possibility of manual interaction with the GUI, but this was never seriously considered.\n\n\n\n      ___\n  _.-|   |           /\\_/\\   (`\\\n {   |   |          (o.o )__ _) )\n  \"-.|___|        _.&gt; ^ &lt;   `  /\n  .--'-`-.     _((_ ` --  /_&lt;  \\\n.+|______|__.-||__)`-'(((/  (((/\n\n\n\nRobot Play\nIn order to interact with the GUI in an automated fashion we needed to implement a robot capable of controlling a web-browser. This robot would in turn be governed by Gatai. The robot is required to start and load the video-game from its base URL. In order for Gatai to evaluate the board on the computer screen, the robot needs to take and return a screenshot to be evaluated by Gatai. This evaluation will return suggested move, communicated back to the robot, and made on the actual game-board. Once the moves have been made and the board has been updated, a new screenshot is taken; and the process repeats itself until the game is over. Figure 5.1 shows an overview of the workflow hitherto described.\n\n\n\n\n\n%%{init: {'theme': 'dark', \"flowchart\": { \"curve\": \"straight\"}}}%%\nflowchart LR\n    A --&gt; |start| B\n    A[GatAI] --&gt;|moves| B[Robot]\n    B --&gt;|load| C[Chrome]\n    B --&gt;|play moves| C\n    C --&gt;|screenshot| B\n    B --&gt;|screenshot| A\n\n\nFigure 5.1: Basic Workflow for Automated Interaction\n\n\n\n\nSelenium is our go-to solution when browser automation is required. Given the prior implementation of Gatai, it made sense to interact with Selenium using the package available on CRAN (Harrison 2022)."
  },
  {
    "objectID": "computer-vision-model.html#screenshot-evaluation",
    "href": "computer-vision-model.html#screenshot-evaluation",
    "title": "5  Computer Vision",
    "section": "5.2 Screenshot Evaluation",
    "text": "5.2 Screenshot Evaluation\nOpening a URL, taking, screenshot to Gatai, are all relatively trivial operations with the infrastructure provided by Harrison (2022). Making moves on the board is a little more cumbersome, but amounts to calculating the coordinates of the grid, and translating the moves returned by Gatai to these coordinates.\nThe real bottleneck in this workflow is the transition from a graphic format (in this case a png format) to a board matrix which Gatai can evaluate."
  },
  {
    "objectID": "computer-vision-model.html#analysis",
    "href": "computer-vision-model.html#analysis",
    "title": "5  Computer Vision",
    "section": "5.3 Analysis",
    "text": "5.3 Analysis\nWe start with a screenshot from the play interface. This is the raw material returned from Selenium.\n\n\n\n\n\nFigure 5.2: Screenshot from X-mas-3: Taken by Robot\n\n\n\n\n\nBoard on Screen\nThe board area is a subset of this screen and we can crop it.\n\n\n\n\n\nFigure 5.3: Screenshot from X-mas-3: Taken by Robot\n\n\n\n\nFrom this board we can calculate the tile centroids and create a grid.\n\n\n\n\n\nFigure 5.4: Board Surface with Coordinate Grid\n\n\n\n\nWe are now able to extract the individual tiles from the board on the computer screen.\n\n\n\n\n\n\n\nStar\n\n\n\n\n\n\n\nRed\n\n\n\n\n\n\n\nSpotted\n\n\n\n\n\n\n\nWreath\n\n\n\n\n\n\n\n\n\nStocking\n\n\n\n\n\n\n\nCandy\n\n\n\n\n\n\n\nBerries\n\n\n\n\n\n\n\nTree\n\n\n\n\n\n\n\n\n\nStriped\n\n\n\n\n\n\n\nHat\n\n\n\n\nFigure 5.5: Example tiles, with nomenclature added.\n\n\nNow that we have these tiles at our disposal, in binary format, our first inclination was to define a set of reference tiles and simply compare the tile in question with the reference one, on a byte by byte basis. The problem with this approach is that there exist minute differences between like tiles, probably due to imprecisions introduces when cropping, as well as screen-resolution issues etcetera. These discrepancies are big enough that a direct comparison is impossible, or at least impracticable."
  },
  {
    "objectID": "computer-vision-model.html#algorithm-for-classification",
    "href": "computer-vision-model.html#algorithm-for-classification",
    "title": "5  Computer Vision",
    "section": "5.4 Algorithm for Classification",
    "text": "5.4 Algorithm for Classification\nImage classification can be done with a series of algorithms –support vector machines (SVM), convoluted neural networks (CNN), k-nearest neighbors etcetera. However, given the very restricted space, and the presumably very small within-class differences (they are in principle identical, differences are introduced by imperfections in the data-retrieval procedures), we decided that multinomial logistic regression would be the correct choice for this use case. This is conveniently implemented in the nnet (Venables and Ripley 2002) package, available open source on the CRAN network."
  },
  {
    "objectID": "computer-vision-model.html#multinomial-logistic-regression",
    "href": "computer-vision-model.html#multinomial-logistic-regression",
    "title": "5  Computer Vision",
    "section": "5.5 Multinomial Logistic Regression",
    "text": "5.5 Multinomial Logistic Regression\nMultinominal Logistic Regression is a classification model, which fits the likelihood of membership in a specified set of classes to a vector of variables. For our purposes we will always use the classification with the highest likelihood as our hard prediction.\n\nTraining Data\nIn order to train the data I classified 254 tiles into the ten known classes. Each tile then ran through a color analysis which parsed the image file, reduced the colors-space to Red, Green and Blue and calculated mean and standard deviation of these primary colors, as well as for each quadrant of the tile. The latter procedure was included with the intention of including shape. All the operations mentioned in this paragraph were conducted using the open source magick (Ooms 2023) package.\n\n\nModel Testing\nThe standard way to test a classification model is to hold out some percentage of the data (typically 20%) and then use that to test the model post-hoc, by using the model to predict the class of this subset and comparing the results. In this case, however, given the paucity of traning data, and the unusually restricted space within which we are operating I chose to use all the classified data and testing the model by predicting a sample of the unclassified tiles, on the assumption that a visual scan of the resulting data would be sufficient to asses the solidity of the model.\n\n\nCode\nmy_tiles &lt;- dir(image_path,full.names = TRUE)\n# Filter for the unclassified tiles\nmy_tiles &lt;- my_tiles[!my_tiles%in%my_data$image] \n\n\n\n\nSpot Check\nTo do a quick spot-check we can select a tile at random and review the prediction.\n\ntile &lt;- sample(my_tiles,1) # Get a random tile\nimage_read(tile) |&gt; print(info=FALSE)\n\n\n\n\nFigure 5.6: A Random Tile for Spot Check\n\n\n\n\n\nimage_data &lt;- color_analysis(tile)\np &lt;- predict(GataiVision,image_data,type=\"prob\")\n\n\n\n\nGatai Vision Evaluation \n\n\nType\nProbability\n\n\n\n\nred\n0.9997103410112713195445622\n\n\nspotted\n0.0002211418040151853238971\n\n\nstar\n0.0000369770498771822541404\n\n\ncandy\n0.0000292945830748471168828\n\n\nhat\n0.0000012137948590184630043\n\n\nwreath\n0.0000008976744968606771867\n\n\nberries\n0.0000000717880923357845433\n\n\nstocking\n0.0000000609678188558140273\n\n\nstriped\n0.0000000013264942843458697\n\n\ntree\n0.0000000000000000002205852\n\n\n\n\n\nWe see that Gatai is quite convinced of its classification of the tile in Figure 5.6, which is has never seen before.\n\n\nModel Evaluation\nWe can now run the rest of the tiles through the model to see what happens. These correspond to tiles that Gatai has never seen before. In total we ran 526 unseen tiles through the model with perfect precision. I am repeating the five first classifications if each class below, for brevity, and to illustrate the alternative evaluation method. By grouping the tiles by classification it is easy for a human to scan and see if there is an odd one out.\n\n\nCode\nanalysis &lt;- color_analysis(my_tiles)\npred &lt;- predict(GataiVision, newdata = analysis)\nmy_new_data &lt;- data.frame(png = my_tiles, pred = pred) |&gt;\n  arrange(pred)\n\n\n\n\n\n\n    \n\n\nFigure 5.7: Classified as: berries by GataiVision\n\n\n\n\n\n\n    \n\n\nFigure 5.8: Classified as: candy by GataiVision\n\n\n\n\n\n\n    \n\n\nFigure 5.9: Classified as: hat by GataiVision\n\n\n\n\n\n\n    \n\n\nFigure 5.10: Classified as: red by GataiVision\n\n\n\n\n\n\n    \n\n\nFigure 5.11: Classified as: spotted by GataiVision\n\n\n\n\n\n\n    \n\n\nFigure 5.12: Classified as: star by GataiVision\n\n\n\n\n\n\n    \n\n\nFigure 5.13: Classified as: stocking by GataiVision\n\n\n\n\n\n\n    \n\n\nFigure 5.14: Classified as: striped by GataiVision\n\n\n\n\n\n\n    \n\n\nFigure 5.15: Classified as: tree by GataiVision\n\n\n\n\n\n\n    \n\n\nFigure 5.16: Classified as: wreath by GataiVision\n\n\n\n\n\n\n\n\n  /\\_/\\\n ( @.@ )\n  &gt; ^ &lt;\n\n I see.\n\n\nWe can now distinguish the tiles from one another and effectively automate the interaction with the live video-game.\n\n\n\n\nHarrison, John. 2022. “RSelenium: R Bindings for ’Selenium WebDriver’.” https://docs.ropensci.org/RSelenium/.\n\n\nOoms, Jeroen. 2023. “Magick: Advanced Graphics and Image-Processing in r.”\n\n\nVenables, W. N., and B. D. Ripley. 2002. “Modern Applied Statistics with s.” https://www.stats.ox.ac.uk/pub/MASS4/."
  },
  {
    "objectID": "showdown.html#arcade-mode",
    "href": "showdown.html#arcade-mode",
    "title": "6  The Showdown",
    "section": "6.1 Arcade Mode",
    "text": "6.1 Arcade Mode\nThe trained AI played five 100-move games — this is the default setup for an arcade game. Gatai used a 4x4 strategy, scanning the board for the highest values move or move sequence and then made that move. We had also programmed in a security valve allowing Gatai to make a random move if no playable move sequence was found. This was, however, never activated1.\nThe results are displayed in Figure 6.1, and show a solid performance in line with our expectations.\n\n\n\n\n\nFigure 6.1: Gatai’s Scores Playing X-mas-3 via GUI"
  },
  {
    "objectID": "showdown.html#time-mode",
    "href": "showdown.html#time-mode",
    "title": "6  The Showdown",
    "section": "6.2 Time Mode",
    "text": "6.2 Time Mode\nTwo games were also played in time mode. For the time-mode version of the game, Gatai would still scan the board for the best moves, but then, if more than one move or move sequence is possible, try to make all of then, in a pattern that minimizes the risk for interference between the moves, and maximizes the likelihood of a high score. In this format Gatai was able to score as high as 7850, however, this measurement is of lesser interest, since it is mostly a function of Gatai’s ability to make moves fast, which in turn depends on the computer hardware rather than the AI implemented.\n\n\n\n\n\n\nGame over... \n    \n    []\n\\\\\\\\\\/////   /\\    \n \\\\\\\\////   //\\\\    *\n ______________\n\n\n\n  /\\_/\\\n (⌐■_■ ) \n  &gt; ^ &lt;\n Hasta la vista, baby."
  },
  {
    "objectID": "showdown.html#footnotes",
    "href": "showdown.html#footnotes",
    "title": "6  The Showdown",
    "section": "",
    "text": "It can be proven mathematically that this will always be the case.↩︎"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "“Gato: The Free Social Gaming Platform for All.” 2023. https://www.gato.us.\n\n\nHarrison, John. 2022. “RSelenium: R Bindings for ’Selenium\nWebDriver’.” https://docs.ropensci.org/RSelenium/.\n\n\nISO. 2012. ISO/IEC 14882:2011 Information\ntechnology — Programming languages — C++. Geneva,\nSwitzerland: International Organization for Standardization. http://www.iso.org/iso/iso_catalogue/catalogue_tc/catalogue_detail.htm?csnumber=50372.\n\n\nOoms, Jeroen. 2023. “Magick: Advanced Graphics and\nImage-Processing in r.”\n\n\nPro Games Studio. 2023. “X-MAS-3.” https://www.gato.us.\n\n\nProellochs, Nicolas, and Stefan Feuerriegel. 2020.\n“ReinforcementLearning: Model-Free Reinforcement Learning.”\n\n\nR Core Team. 2023. R: A Language and Environment for Statistical\nComputing. Vienna, Austria: R Foundation for Statistical Computing.\nhttps://www.R-project.org/.\n\n\nVenables, W. N., and B. D. Ripley. 2002. “Modern Applied\nStatistics with s.” https://www.stats.ox.ac.uk/pub/MASS4/.\n\n\nWatkins, Christopher JCH, and Peter Dayan. 1992.\n“Q-Learning.” Machine Learning 8: 279–92."
  },
  {
    "objectID": "implementation-and-scalability.html#reinforcement-learning",
    "href": "implementation-and-scalability.html#reinforcement-learning",
    "title": "Appendix A — Scalability",
    "section": "A.1 Reinforcement Learning",
    "text": "A.1 Reinforcement Learning\nThis algorithm is already available and implemented open source in C++, which is considerably more efficient (albeit equally accurate) than the R implementation of the same. The algorithm is also available from all of the major cloud providers (Amazon Web Services, Google Cloud, Microsoft Azure) and in a production environment this would be the obvious go-to for implementation as it would not only decrease the time needed for training (due to parallel processing) but also provide the convenience afforded by its streamlined integration into already existing work-flows of cloud-based systems."
  },
  {
    "objectID": "implementation-and-scalability.html#vision-model",
    "href": "implementation-and-scalability.html#vision-model",
    "title": "Appendix A — Scalability",
    "section": "A.2 Vision Model",
    "text": "A.2 Vision Model\nComputer vision is also widely available from cloud providers, however, given the very restricted field of vision required for a video-game, it is highly unlikely that anything is gained from using these general purpose models. In fact, it is easily argued that their implementation might be counter-productive. As an example the model trained for X-mas-3 only used ~250 input cases and returned in &lt; 0.5 seconds with perfect accuracy, all on commodity hardware."
  },
  {
    "objectID": "implementation-and-scalability.html#gui-by-pass",
    "href": "implementation-and-scalability.html#gui-by-pass",
    "title": "Appendix A — Scalability",
    "section": "A.3 GUI By-Pass",
    "text": "A.3 GUI By-Pass\nIdeally, a production level implementation will include access to the source-code of the game under scrutiny. This will obviate some of the need to recreate and/or abstract the game in question as we would be able run the back-end part of the source without the need to interact with a GUI and its corresponding vision model, which would facilitate the setup of the training tasks and consequently reduce time-to-production by orders of magnitude."
  },
  {
    "objectID": "business-case.html#sec-eureka",
    "href": "business-case.html#sec-eureka",
    "title": "Appendix B — Business Cases",
    "section": "B.1 Eureka",
    "text": "B.1 Eureka\nPerhaps most closely related to the original intention of the undertaking is the generation of insight. Learning how to play the games available on the platform (or in principle not necessarily) at scale, may uncover patterns which are not readily available through the application of heuristic methods and thus provide deeper understanding of the games available and by extension their users. This in turn will allow for better targeting of advertisements and upsales, which are two of the company’s income-streams.\n\nGenerative Gatai\nGato furthermore aspires to apply generative AI in order to create games customized to each user’s preferences. A deep understanding of existing games is a fundamental input to any generative algorithm we devise for this purpose."
  },
  {
    "objectID": "business-case.html#tactical-derivatives",
    "href": "business-case.html#tactical-derivatives",
    "title": "Appendix B — Business Cases",
    "section": "B.2 Tactical Derivatives",
    "text": "B.2 Tactical Derivatives\nThere is a potentially long list of directly productizable derivatives attainable from the exercise we undertook. These can all be converted in short-term wins in the sense that while the strategic goals laid out in Section B.1 are longer-term, the partial results can be applied on a case-by-case basis.\n\nGatai Assist\nGatai Assist will monitor the players game. If the player seems stuck Gatai Assist will intervene and propose the best move in the position: tactical or strategic. Gatai Assist will offer to (a) indicate the best move or (b) play it directly on the player’s board.\n\n\nGatai Tutor\nIn the Gatai Tutor implementation, Gatai observes a game played, analyzes it and provides this analysis to the player after the game or on request.\nFor the case of X-mas-3 this may seem trivial, but for more complex puzzles, where skill is a more important factor the tutor will be more valuable to the user.\n\n\nGatai Extra Player\nThis application relates to multi-player games. With knowledge of how to play the game in question, Gatai can take on or several seats in a multi-player game, and thus make the experience more interesting for the user. If, for example, I have the urge to play Bridge at 4am in the morning in my time-zone, and I can only find two more insomniacs to join me, I would be able to call on Gatai to fill the fourth chair.\n\n\nCheat-Bots\nThere exists a category of software products, aimed at gamers, known as cheat-bots. These AI agents allow the player to play at a higher level than their normal game and thus attain a higher score. Cheat-bots are also used in multi-level games, when the player is tired of the lower levels, and wants a quick path to the higher more challenging levels of the game in question.\nIt is easy to see how AI knowledge, on the scale of AI intuition to solution of a game will provide the raw-materials for producing such software products even one game at a time."
  }
]