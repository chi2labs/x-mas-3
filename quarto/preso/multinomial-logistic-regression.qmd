---
bibliography: references.bib
---

## Multinomial Logistic Regression

*Multinominal Logistic Regression* is a classification model, which fits the likelihood of membership in a specified set of classes to a vector of variables. For our purposes we will always use the classification with the highest likelihood as our hard prediction.

### Training Data

```{r}
#| label: multinomial-regression-setup
#| include: false
library(xmas3)
library(dplyr)
library(nnet)
library(magick)
set.seed(2023)
image_path <- here::here("inst","image-data","ui-tiles")
my_data <- 
  readr::read_csv(here::here("inst","training-data","image-classification.csv"))
my_data$image <- stringr::str_replace(my_data$image,"/cloud/project/",'')
my_color_analysis <- color_analysis(here::here(my_data$image))
my_data <- bind_cols(my_data,my_color_analysis)
GataiVision <- nnet::multinom(class~.,data = my_data |> select(-image,-time))

saveRDS(GataiVision, here::here("models/gatai_vision.rds") )

```

In order to train the data I classified `r nrow(my_data)` tiles into the ten known classes. Each tile then ran through a color analysis which parsed the image file, reduced the colors-space to Red, Green and Blue and calculated mean and standard deviation of these primary colors, as well as for each quadrant of the tile. The latter procedure was included with the intention of including shape. All the operations mentioned in this paragraph were conducted using the open source *magick* [@magick] package.

### Model Testing

The *standard* way to test a classification model is to hold out some percentage of the data (typically 20%) and then use that to test the model *post-hoc,* by using the model to predict the class of this subset and comparing the results. In this case, however, given the paucity of traning data, and the unusually restricted space within which we are operating I chose to use all the classified data and testing the model by predicting a sample of the unclassified tiles, on the assumption that a visual scan of the resulting data would be sufficient to asses the solidity of the model.

```{r}
#| code-fold: true

my_tiles <- dir(image_path,full.names = TRUE)
# Filter for the unclassified tiles
my_tiles <- my_tiles[!my_tiles%in%my_data$image] 
```

### Spot Check

To do a quick spot-check we can select a tile at random and review the prediction.

```{r}
#| label: fig-random-tile
#| fig-cap: "A Random Tile for Spot Check"
tile <- sample(my_tiles,1) # Get a random tile
image_read(tile) |> print(info=FALSE)
```

```{r}
image_data <- color_analysis(tile)
p <- predict(GataiVision,image_data,type="prob")
```

```{r}
#| echo: false
#| label: prediction-table-gatai-vision
#| tbl-cap: "Gatai Vision Evaluation"
data.frame(Type = names(p),p = p) |> 
  arrange(desc(p)) |> 
  mutate(Probability = format(p, scientific = FALSE)) |> 
  select(Type,Probability) |> 
  knitr::kable(row.names = FALSE)
```

We see that Gatai is quite convinced of its classification of the tile in @fig-random-tile, which is has never seen before.

### Model Evaluation

We can now run the rest of the tiles through the model to see what happens. These correspond to tiles that Gatai has never seen before. In total we ran 526 unseen tiles through the model with perfect precision. I am repeating the five first classifications if each class below, for brevity, and to illustrate the alternative evaluation method. By grouping the tiles by classification it is easy for a human to scan and see if there is an odd one out.

```{r}
#| code-fold: true
analysis <- color_analysis(my_tiles)
pred <- predict(GataiVision, newdata = analysis)
my_new_data <- data.frame(png = my_tiles, pred = pred) |>
  arrange(pred)
```

```{r}
#| echo: false
#| results: asis

# for(i in 1:nrow(probs)){
#   cat("\n",paste0("![](","docs/tile-images/",
#                   basename(my_files[i]),
#                   ")"),"\n") 
#   cat("\n* ",probs$prediction[i],"\n")
# }

purrr::walk(my_new_data$pred |> as.character() |> unique(),~{
  
  cat(paste0("::: {#fig-tiles-",.x," layout-nrow=2}\n"))
  my_new_data |> filter(pred==.x) |> pull(png) |> head(5) |> 
    purrr::walk(~{
      cat("",paste0("![](","./ui-tiles/",basename(.x),")"),"\n") 
    })
  cat("\n")
  cat("Classified as: ",as.character(.x)," by GataiVision\n")
  cat(":::\n")
})
```

::: column-margin
```{r}
#| echo: false
ascii_gatai("isee") |> cat("I see.")
```
:::

```{r}
#| echo: false
#| results: asis
#| include: false

# cat("### Training Data \n")
# purrr::walk(my_data$class |> as.character() |> unique(),~{
#   
#   cat(paste0("::: {#fig-tiles-",.x," layout-nrow=2}\n"))
#   my_data |> filter(.data$class==.x) |> pull(image) |> 
#     purrr::walk(~{
#       cat(basename(.x),paste0("![",basename(.x),"](","./ui-tiles/",basename(.x),")"),"\n") 
#     })
#   cat("\n")
#   cat(as.character(.x),"\n")
#   cat(":::\n")
# })
```
